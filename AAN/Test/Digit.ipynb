{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bd135bbaf031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pylab'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "* [Pytorch Transform Documentation](http://pytorch.org/docs/torchvision/transforms.html)\n",
    "\n",
    "\n",
    "1. **torchvision.transforms.Compose:** Composes several transforms together. \n",
    "2. **torchvision.transforms.ToTensor:** Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]. \n",
    "3. **dataloader.DataLoader:** [https://pytorch.org/docs/stable/data.html] Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset.\n",
    "4. **torch.nn.functionnal :** [http://pytorch.org/docs/_modules/torch/nn/functional.html]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Téléchargement des données\n",
    "train = MNIST('./data', train=True, download=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(), # ToTensor effectue une normalisation min-max.\n",
    "]), )\n",
    "\n",
    "test = MNIST('./data', train=False, download=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(), # ToTensor effectue une normalisation min-max.\n",
    "]), )\n",
    "\n",
    "# Création du DataLoader\n",
    "dataloader_args = dict(shuffle=True, batch_size=64, num_workers=1, pin_memory=True)\n",
    "train_loader = dataloader.DataLoader(train, **dataloader_args)\n",
    "test_loader = dataloader.DataLoader(test, **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des informations des corpus\n",
    "\n",
    "train_data = train.train_data\n",
    "train_data = train.transform(train_data.numpy())\n",
    "test_data = test.test_data\n",
    "test_data = test.transform(test_data.numpy())\n",
    "\n",
    "print('[Train]')\n",
    "print(' - Numpy Shape:', train.train_data.cpu().numpy().shape)\n",
    "print(' - Tensor Shape:', train.train_data.size())\n",
    "print(' - Transformed Shape:', train_data.size())\n",
    "print(' - min:', torch.min(train_data))\n",
    "print(' - max:', torch.max(train_data))\n",
    "print(' - mean:', torch.mean(train_data))\n",
    "print(' - std:', torch.std(train_data))\n",
    "print(' - var:', torch.var(train_data))\n",
    "print('[Test]')\n",
    "print(' - Numpy Shape:', test.test_data.cpu().numpy().shape)\n",
    "print(' - Tensor Shape:', test.test_data.size())\n",
    "print(' - Transformed Shape:', test_data.size())\n",
    "print(' - min:', torch.min(test_data))\n",
    "print(' - max:', torch.max(test_data))\n",
    "print(' - mean:', torch.mean(test_data))\n",
    "print(' - std:', torch.std(test_data))\n",
    "print(' - var:', torch.var(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage de quelques images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20, 8))\n",
    "columns = 8\n",
    "rows = 1\n",
    "for i in range(1, columns*rows +1):\n",
    "    idx = np.random.randint(60000)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(train.train_data[idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle feed-forward (pour exemple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model FeedForward pour exemple\n",
    "class FFModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FFModel, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(784, 548)\n",
    "        self.bc1 = nn.BatchNorm1d(548)\n",
    "        self.fc2 = nn.Linear(548, 252)\n",
    "        self.bc2 = nn.BatchNorm1d(252)\n",
    "        self.fc3 = nn.Linear(252, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # flatten 28x28 = 784\n",
    "        x = x.view((-1, 784))\n",
    "        # couche entièrement connectée 784 -> 548\n",
    "        h = self.fc1(x)\n",
    "        # batch normalization\n",
    "        h = self.bc1(h)\n",
    "        # ReLU\n",
    "        h = F.relu(h)\n",
    "        # Dropout avec probabilité .5\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        \n",
    "        # couche entièrement connectée 548 -> 252\n",
    "        h = self.fc2(h)\n",
    "        h = self.bc2(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=0.2, training=self.training)\n",
    "        \n",
    "        # couche entièrement connectée 252 -> 10\n",
    "        h = self.fc3(h)\n",
    "        # estimation de la distribution de probabilités avec softmax\n",
    "        out = F.log_softmax(h, dim=1)\n",
    "        return out\n",
    "\n",
    "ff_model = FFModel()\n",
    "#model.cuda() # CUDA! (si on a un GPU)\n",
    "ff_optimizer = optim.Adam(ff_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle convolutionnel (à compléter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutionnal model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # TODO: déclaration des variables membres utilisées dans forward()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # TODO: Exemple de modèle\n",
    "        # Q0: Afficher la taille des données x, vous devez trouver 64x1x28x28\n",
    "        # 1.1 Convolution 2d avec 5 filtres (channels). Noyau de taille 5\n",
    "        # Q1.1: Quelle sera la taille après convolution ?\n",
    "        # 1.2 Max pooling (taille du noyau = 2) + ReLU\n",
    "        # Q1.2: Quelle sera la taille cette opération ?\n",
    "        \n",
    "        # 2.1 Convolution 2d avec 10 filtres (channels). Noyau de taille 5\n",
    "        # Q2.1: Quelle sera la taille après convolution ?\n",
    "        # 2.2 Dropout\n",
    "        # -> voir torch.nn.Dropout2d\n",
    "        # 2.3 Max pooling (taille du noyau = 2) + ReLU\n",
    "        # -> voir torch.nn.Functionnal.max_pool2d, torch.nn.Functionnal.ReLU\n",
    "        # Q1.2: Quelle sera la taille cette opération ?\n",
    "        \n",
    "        # 3. Couche entièrement connectée (essayer linéaire, non-linéaire), taille de sortie au choix\n",
    "        # 4.1 Couche entièrement connectée (essayer linéaire, non-linéaire), taille de sortie = 10\n",
    "        # -> voir torch.nn.Linear, torch.nn.Linear, torch.nn.Tanh, torch.nn.Sigmoid\n",
    "        # 4.2 return softmax -> torch.nn.Functionnal.log_softmax\n",
    "        \n",
    "        return result\n",
    "\n",
    "    \n",
    "cnn_model = CNNModel()\n",
    "#cnn_model.cuda() # CUDA! @\n",
    "cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Boucle principale d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs=3\n",
    "\n",
    "cnn_model.train()\n",
    "cnn_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Get Samples\n",
    "        #data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        # TODO: Remise à zéro des gradients\n",
    "        \n",
    "        # TODO: Prédiction\n",
    "        pred = cnn_model(data) \n",
    "        # Calculer la cross_entropy loss\n",
    "        # -> voir torch.nn.Functionnal.cross_entropy\n",
    "        loss = ...\n",
    "        \n",
    "        # Sauvegarde des losses pour affichage\n",
    "        cnn_losses.append(loss.data.item())\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Affichage\n",
    "        if batch_idx % 100 == 0 or batch_idx % 100 == 1 :\n",
    "            print('\\r Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}'.format(\n",
    "                    epoch, \n",
    "                    batch_idx * len(data), \n",
    "                    len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), \n",
    "                    loss.data.item()), \n",
    "                    end='')\n",
    "            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Affichage de l'erreur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "x = np.linspace(0, len(cnn_losses), len(cnn_losses))\n",
    "fig = plt.figure(figsize=(13, 8)) \n",
    "ax = fig.add_subplot(1,1,1)\n",
    "cnn_line, = ax.plot(x, cnn_losses)\n",
    "\n",
    "def update_losses(smooth=51):\n",
    "    cnn_line.set_ydata(savgol_filter(cnn_losses, smooth, 3))\n",
    "    fig.canvas.draw()\n",
    "\n",
    "interact(update_losses, smooth=(5, 201, 2));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA (si on a des GPUs)\n",
    "#evaluate_x = Variable(test_loader.dataset.test_data.type_as(torch.FloatTensor())).cuda()\n",
    "#evaluate_y = Variable(test_loader.dataset.test_labels).cuda()\n",
    "evaluate_x = Variable(test_loader.dataset.test_data.type_as(torch.FloatTensor()))\n",
    "evaluate_x = evaluate_x.reshape(10000, 1, 28, 28)\n",
    "evaluate_y = Variable(test_loader.dataset.test_labels)\n",
    "\n",
    "# TODO: appliquer le modèle sur les données de test\n",
    "output = ...\n",
    "# TODO récupérer les classes les plus probables\n",
    "pred = ...\n",
    "# calculer la précision\n",
    "d = pred.eq(evaluate_y.data).cpu()\n",
    "#print(\"d:\", d, \" sum:\", d.sum())\n",
    "accuracy = d.sum().type_as(torch.FloatTensor())/d.size()[0]\n",
    "\n",
    "print('{} Accuracy:'.format(model_type), accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
